{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "\n",
    "\n",
    "from itertools import count\n",
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tnrange\n",
    "from random import choice\n",
    "\n",
    "from complex_gridword import GridworldEnv\n",
    "from nets import *\n",
    "from draw_methods import *\n",
    "from hyper_parametrs import *\n",
    "from env_methods import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from utils import command\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shutil.rmtree(logs_directory)\n",
    "writer = SummaryWriter(logs_directory)\n",
    "board = command.Command('tensorboard --logdir=run1:{} --port {}'.format(logs_directory, board_port))\n",
    "board.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./plots/simple_5x5_siamese/hyper_parametrs.py'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy(\"hyper_parametrs.py\", logs_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrejklimkin/anaconda/lib/python3.5/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['choice']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_size = (5, 5)\n",
    "env_name = \"simple\"\n",
    "grid_map = np.load(\"gridworlds_data/{}_{}x{}/grid_map.npy\".format(env_name, grid_size[0], grid_size[1]))\n",
    "env = GridworldEnv(grid_size, grid_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_dim = int(env.nS * 2)\n",
    "action_dim = int(env.nA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy_term(probs):\n",
    "    return -torch.sum(probs * torch.log(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_params(agent, optimizer, losses_history):\n",
    "    R = 0\n",
    "    saved_actions = agent.saved_actions\n",
    "    value_loss = 0\n",
    "    rewards = []\n",
    "    for r in agent.rewards[::-1]:\n",
    "        R = r + gamma_rl * R\n",
    "        rewards.insert(0, R)\n",
    "    rewards = torch.Tensor(rewards)\n",
    "    log_loss = Variable(torch.FloatTensor([0]))\n",
    "    val_loss = Variable(torch.FloatTensor([0]))\n",
    "    entropy_loss = Variable(torch.FloatTensor([0]))\n",
    "    for (action, probs, value), r in zip(saved_actions, rewards):\n",
    "        m = torch.distributions.Categorical(probs)\n",
    "        reward = r - value.data[0, 0]\n",
    "        log_loss  += -(m.log_prob(action[0]) * reward)\n",
    "        val_loss += lambda_baseline * F.mse_loss(value, Variable(torch.Tensor([r])))\n",
    "        entropy_loss += -entropy_weights[\"agent\"] * entropy_term(probs)\n",
    "    \n",
    "    losses_history[\"entropy\"].append(entropy_loss.data.numpy()[0])\n",
    "    losses_history[\"value loss\"].append(val_loss.data.numpy()[0])\n",
    "    losses_history[\"log loss\"].append(log_loss.data.numpy()[0])\n",
    "    loss = log_loss + val_loss + entropy_loss\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    del agent.rewards[:]\n",
    "    del agent.saved_actions[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env_type = \"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Expert_left_corner = NovelExpert(\"left_top_corner\", np.load(\"gridworlds_data/{}_{}x{}/agents_left_corner/action_probs.npy\".format(env_name, grid_size[0], grid_size[1])), \n",
    "                            np.load(\"gridworlds_data/{}_{}x{}/agents_left_corner/value_function.npy\".format(env_name, grid_size[0], grid_size[1])),\n",
    "                            np.load(\"gridworlds_data/{}_{}x{}/agents_left_corner/goal_map.npy\".format(env_name, grid_size[0], grid_size[1])))\n",
    "Expert_right_corner = NovelExpert(\"right_bottom_corner\", np.load(\"gridworlds_data/{}_{}x{}/agents_right_corner/action_probs.npy\".format(env_name, grid_size[0], grid_size[1])), \n",
    "                            np.load(\"gridworlds_data/{}_{}x{}/agents_right_corner/value_function.npy\".format(env_name, grid_size[0], grid_size[1])),\n",
    "                            np.load(\"gridworlds_data/{}_{}x{}/agents_right_corner/goal_map.npy\".format(env_name, grid_size[0], grid_size[1])))\n",
    "Expert_global_optimal = NovelExpert(\"global_optimal\", np.load(\"gridworlds_data/{}_{}x{}/agents_global_optimal/action_probs.npy\".format(env_name, grid_size[0], grid_size[1])), \n",
    "                            np.load(\"gridworlds_data/{}_{}x{}/agents_global_optimal/value_function.npy\".format(env_name, grid_size[0], grid_size[1])),\n",
    "                            np.load(\"gridworlds_data/{}_{}x{}/agents_global_optimal/goal_map.npy\".format(env_name, grid_size[0], grid_size[1])))\n",
    "possible_s_stars = [0, env.nS - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siamese_net = torch.load(\"pretrained_nets/siamese_{}_{}x{}.pt\".format(env_name, grid_size[0], grid_size[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_true_d = 0 \n",
    "\n",
    "for s1 in range(env.nS):\n",
    "    for s2 in range(env.nS):\n",
    "        if env.grid_map[s1] and env.grid_map[s2]:\n",
    "            max_true_d = max(max_true_d, abs(s1 % int(np.sqrt(env.nS)) - s2 % int(np.sqrt(env.nS))) + abs(s1 // int(np.sqrt(env.nS)) - s2 // int(np.sqrt(env.nS))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def goal_unsim(env, g1, g2, metric_type='siamnet'):\n",
    "    #print(g1)\n",
    "    #print(g2)\n",
    "    if metric_type =='siam':\n",
    "        return (1.0 - siamese_net(np.array([(g1, g2)]))).data.numpy()[0][0]\n",
    "    else:\n",
    "        global env_type\n",
    "        if env.grid_map[g1] == 0 or env.grid_map[g2] == 0:\n",
    "                return 1000\n",
    "        if env_type == \"simple\" or \"pillar\":\n",
    "            return (abs(g1 % int(np.sqrt(env.nS)) - g2 % int(np.sqrt(env.nS))) + abs(g1 // int(np.sqrt(env.nS)) - g2 // int(np.sqrt(env.nS)))) /  max_true_d\n",
    "        else:\n",
    "            if env.grid_map[g1] == 0 or env.grid_map[g2] == 0:\n",
    "                return 1000\n",
    "            r1 = np.abs(Expert_left_corner.v_function[g1] - Expert_left_corner.v_function[g2])\n",
    "            r2 = np.abs(Expert_right_corner.v_function[g1] - Expert_right_corner.v_function[g2])\n",
    "            return min(r1, r2) /  max_true_d\n",
    "    \n",
    "    \n",
    "def goal_based_training(env, tmax, agent, goal, optimizer, losses_history, agent_type): \n",
    "    time = 0\n",
    "    done = False\n",
    "    while True:\n",
    "        if is_terminal(env, env.s): #done\n",
    "            break\n",
    "        time += 1\n",
    "        a = agent.select_action(env.s, goal)\n",
    "        state, _, done, _= env.step(a[0, 0])\n",
    "        if is_terminal(env, env.s):\n",
    "            if is_terminal(env, env.s): #done\n",
    "                break\n",
    "        if time >= tmax:\n",
    "            break\n",
    "        agent.rewards.append(0)\n",
    "    \n",
    "    if \"goal-based\" in agent_type:\n",
    "        final_reward = (-time - lambda_goals  * goal_unsim(env, goal, env.s, agent.metric_type)) / scale_reward \n",
    "    else:\n",
    "        final_reward = (-time) / scale_reward \n",
    "    agent.rewards.append(final_reward)\n",
    "    if(len(agent.saved_actions)):\n",
    "        update_params(agent, optimizer, losses_history)\n",
    "    \n",
    "    del agent.rewards[:]\n",
    "    del agent.saved_actions[:]\n",
    "\n",
    "    return final_reward\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def choose_goal(env, experts, s0, iteration, agent_type=\"goal-based\"):\n",
    "    #print(s0)\n",
    "    if \"goal-based\" in agent_type:\n",
    "        best_goal = None\n",
    "        best_goal_v = -np.inf\n",
    "        possible_goals = [0, env.nS - 1]\n",
    "        for expert in experts:\n",
    "            possible_goals.append(expert.get_goal(s0))\n",
    "            if expert.v_function[s0] > best_goal_v:\n",
    "                best_goal = expert.get_goal(s0)\n",
    "                best_goal_v = expert.v_function[s0]\n",
    "        \n",
    "        if goal_sampling_strategy == \"eps_greedy\":\n",
    "            if np.random.random() < goal_eps:\n",
    "                goal_eps *= goal_eps_decay\n",
    "                return np.random.choice(possible_goals) \n",
    "            else:\n",
    "                return int(best_goal)\n",
    "        \n",
    "        if goal_sampling_strategy == \"random\":\n",
    "            return int(possible_goals[iteration % 2])\n",
    "    return None\n",
    "    \n",
    "def train_agent(env, tmax, each_goal_times, agent, experts, optimizer, losses_history, i, agent_type):\n",
    "    rewards = []\n",
    "    episode_time = []\n",
    "    finish_states = []\n",
    "    set_random_s0(env)\n",
    "    s0 = env.reset()\n",
    "    goal = choose_goal(env, experts, s0, i, agent_type)\n",
    "    res = goal_based_training(env, tmax, agent, goal, optimizer, losses_history, agent_type)   \n",
    "    rewards.append(res)\n",
    "    \n",
    "    return agent, np.array(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_env_s0(env, s0):\n",
    "    env.isd = np.zeros(env.shape[0] * env.shape[1])\n",
    "    env.isd[s0] = 1 \n",
    "\n",
    "def play_n_episodes(n, env, model, s0_list, s_star, tmax=40):\n",
    "    state_dist_list = []\n",
    "    for i in range(n):\n",
    "        set_env_s0(env, s0_list[i])\n",
    "        env.reset()\n",
    "        state_dist_episode = np.zeros(env.shape)\n",
    "        for j in range(tmax):\n",
    "            s = env.s\n",
    "            state_dist_episode[s // env.shape[0]][s % env.shape[1]] += 1\n",
    "            if(is_terminal(env, env.s)):\n",
    "                break\n",
    "            probs, state_value = model(s, s_star)\n",
    "            action = probs.multinomial().data\n",
    "            env.step(action[0][0])\n",
    "        state_dist_list.append(state_dist_episode)\n",
    "    \n",
    "    state_dist = np.zeros(env.shape)\n",
    "    \n",
    "    for dist in state_dist_list:\n",
    "        state_dist += dist\n",
    "    \n",
    "    return state_dist / n, state_dist_list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "plots_dir = \"plots_compare\"\n",
    "try:\n",
    "    shutil.rmtree(plots_dir)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(plots_dir)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses_history_goal_based_true = {\n",
    "    \"entropy\":[],\n",
    "    \"value loss\":[],\n",
    "    \"log loss\":[]\n",
    "}\n",
    "\n",
    "losses_history_goal_based_siam = {\n",
    "    \"entropy\":[],\n",
    "    \"value loss\":[],\n",
    "    \"log loss\":[]\n",
    "}\n",
    "\n",
    "losses_history_simple = {\n",
    "    \"entropy\":[],\n",
    "    \"value loss\":[],\n",
    "    \"log loss\":[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent_goal_based_true = Agent(state_dim, action_dim, \"goal-based\", \"true\")\n",
    "agent_goal_based_siam = Agent(state_dim, action_dim, \"goal-based\", \"siam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrejklimkin/Documents/Coursework/2017-2018/main/source/experts-learning/nets.py:98: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(action_scores), state_values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/andrejklimkin/anaconda/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/andrejklimkin/anaconda/lib/python3.5/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/Users/andrejklimkin/anaconda/lib/python3.5/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 goal based last: -2.4480\n",
      "0 goal based mean: -2.4480\n",
      "0 simple agent last: -3.4060\n",
      "0 simple agent mean: -3.4060\n",
      "####################################################################################################\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ff1ff46d964d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtnrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#agent_goal_based_true, rewards = train_agent(env, tmax, each_goal_times, agent_goal_based_true, experts, optimizer_goal_based_agent, losses_history_goal_based_true, i, agent_type=\"goal-based\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0magent_goal_based_siam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meach_goal_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_goal_based_siam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_goal_based_agent_siam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_history_goal_based_siam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"goal-based\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0magent_simple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meach_goal_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_simple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_simple_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_history_simple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"simple\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-32be169028f9>\u001b[0m in \u001b[0;36mtrain_agent\u001b[0;34m(env, tmax, each_goal_times, agent, experts, optimizer, losses_history, i, agent_type)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0ms0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mgoal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoose_goal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoal_based_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-40b4ea6694ec>\u001b[0m in \u001b[0;36mgoal_based_training\u001b[0;34m(env, tmax, agent, goal, optimizer, losses_history, agent_type)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtime\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_terminal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andrejklimkin/Documents/Coursework/2017-2018/main/source/experts-learning/nets.py\u001b[0m in \u001b[0;36mselect_action\u001b[0;34m(self, state, s_star, cache_action)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m#state = torch.from_numpy(state).int().unsqueeze(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_star\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_action\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andrejklimkin/Documents/Coursework/2017-2018/main/source/experts-learning/nets.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, s, s_star)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m#         state_values = self.value_head(F.relu(self.value_linear(x_value)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0maction_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mstate_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andrejklimkin/anaconda/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andrejklimkin/anaconda/lib/python3.5/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andrejklimkin/anaconda/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stats = defaultdict(list)\n",
    "\n",
    "reset_times = 10\n",
    "\n",
    "for time in range(reset_times):\n",
    "    #agent_goal_based_true = Agent(state_dim, action_dim, \"goal-based\", \"true\")\n",
    "    agent_goal_based_siam = Agent(state_dim, action_dim, \"goal-based\", \"siam\")\n",
    "    agent_simple = Agent(state_dim, action_dim, \"simple\")\n",
    "\n",
    "    #optimizer_goal_based_agent_true = optim.Adam(agent_goal_based.parameters(),lr=lr_agent, weight_decay=weight_decay)\n",
    "    optimizer_goal_based_agent_siam = optim.Adam(agent_goal_based_siam.parameters(),lr=lr_agent, weight_decay=weight_decay)\n",
    "    optimizer_simple_agent = optim.Adam(agent_simple.parameters(),lr=lr_agent, weight_decay=weight_decay)\n",
    "\n",
    "    \n",
    "    each_goal_times = 1\n",
    "    start = 0\n",
    "    models = [agent_goal_based_siam, agent_simple, Expert_global_optimal]\n",
    "    experts = [Expert_global_optimal]\n",
    "    reward_history = defaultdict(list)\n",
    "\n",
    "    estimate_every = 1000\n",
    "    estimation_episodes_num = 500\n",
    "\n",
    "    for i in tnrange(train_steps):\n",
    "        #agent_goal_based_true, rewards = train_agent(env, tmax, each_goal_times, agent_goal_based_true, experts, optimizer_goal_based_agent, losses_history_goal_based_true, i, agent_type=\"goal-based\")\n",
    "        agent_goal_based_siam, rewards = train_agent(env, tmax, each_goal_times, agent_goal_based_siam, experts, optimizer_goal_based_agent_siam, losses_history_goal_based_siam, i, agent_type=\"goal-based\")\n",
    "        agent_simple, rewards = train_agent(env, tmax, each_goal_times, agent_simple, experts, optimizer_simple_agent, losses_history_simple, i, agent_type=\"simple\")\n",
    "\n",
    "        #fig, ax = subplots(nrows=1, ncols=1, figsize=(12, 6))\n",
    "        models = [agent_goal_based_siam, agent_simple, Expert_global_optimal]\n",
    "        models_anotations = [\"goal-based siam-metric agent\", \"simple agent\", \"Expert global optimal\"]\n",
    "\n",
    "\n",
    "        if (i + 1) % estimate_every == 0:\n",
    "\n",
    "            s0_list = np.random.choice(np.array(np.where(env.grid_map)).flatten(), size=estimation_episodes_num)\n",
    "\n",
    "            current_rewards = get_agents_reward(env, models, models_anotations, tmax, possible_s_stars, s0_list, estimation_episodes_num)\n",
    "\n",
    "            for model_name, model_reward in zip(current_rewards.keys(), current_rewards.values()):\n",
    "                reward_history[model_name].append(np.mean(model_reward))\n",
    "    \n",
    "    stats[\"goal based\"].append(reward_history[\"goal-based siam-metric agent\"])\n",
    "    print(\"%d goal based last: %.4f\" % (time, np.array(stats[\"goal based\"])[-1, -1]))\n",
    "    print(\"%d goal based mean: %.4f\" % (time, np.mean(np.array(stats[\"goal based\"])[:, -1], axis=0)))\n",
    "    \n",
    "    stats[\"simple agent\"].append(reward_history[\"simple agent\"])\n",
    "    print(\"%d simple agent last: %.4f\" % (time, np.array(stats[\"simple agent\"])[-1, -1]))\n",
    "    print(\"%d simple agent mean: %.4f\" % (time, np.mean(np.array(stats[\"simple agent\"])[:, -1], axis=0)))\n",
    "    \n",
    "    print(\"#\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-33.8546, -30.5522, -19.695 , -15.7532, -13.9772, -12.9772,\n",
       "       -12.4752, -11.902 , -11.5734, -11.2158, -10.9202, -10.2894,\n",
       "        -9.6354,  -9.4364,  -8.9554,  -9.056 ,  -8.5738,  -8.4132,\n",
       "        -7.9822,  -7.8764,  -7.2082,  -7.1242,  -6.6822,  -6.3096,\n",
       "        -6.347 ,  -6.105 ,  -5.9102,  -5.6952,  -5.6026,  -5.5702])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(stats[\"goal based\"]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(stats).to_csv(\"stats/simple_9x9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1234c3cf8>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAFoCAYAAAA//nPjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIZ+z89wq6kw4XlAgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1234c3d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.mean(np.array(stats[\"goal based\"]), axis=0))\n",
    "plt.plot(np.mean(np.array(stats[\"simple agent\"]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-13.3784,  -5.9348,  -4.8472,  -4.1542,  -3.9472,  -3.845 ,\n",
       "        -3.7452,  -3.7122,  -3.741 ,  -3.628 ,  -3.6458,  -3.6514,\n",
       "        -3.5716,  -3.4908,  -3.4798,  -3.3726,  -3.3496,  -3.1946,\n",
       "        -3.179 ,  -3.188 ,  -3.11  ,  -3.1232,  -3.0876,  -3.0212,\n",
       "        -3.0388])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(stats[\"simple agent\"]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-10.666,  -5.924,  -4.728,  -4.102,  -3.952,  -3.962,  -3.818,\n",
       "         -3.646,  -3.89 ,  -3.7  ,  -3.696,  -3.704,  -3.784,  -3.626,\n",
       "         -3.754,  -3.666,  -3.622,  -3.55 ,  -3.63 ,  -3.54 ,  -3.268,\n",
       "         -3.572,  -3.4  ,  -3.456,  -3.504],\n",
       "       [-15.234,  -5.644,  -4.578,  -4.062,  -3.764,  -3.852,  -3.672,\n",
       "         -3.84 ,  -3.628,  -3.796,  -3.602,  -3.502,  -3.526,  -3.598,\n",
       "         -3.506,  -3.432,  -3.676,  -3.258,  -3.506,  -3.472,  -3.492,\n",
       "         -3.486,  -3.33 ,  -3.124,  -3.054],\n",
       "       [-19.294,  -5.694,  -4.752,  -4.128,  -3.758,  -3.762,  -3.66 ,\n",
       "         -3.834,  -3.558,  -3.802,  -3.584,  -3.542,  -3.174,  -3.206,\n",
       "         -3.324,  -3.052,  -2.908,  -2.592,  -2.706,  -2.484,  -2.646,\n",
       "         -2.57 ,  -2.534,  -2.628,  -2.68 ],\n",
       "       [-20.016,  -7.03 ,  -5.164,  -4.056,  -3.584,  -3.014,  -2.938,\n",
       "         -2.732,  -2.626,  -2.44 ,  -2.458,  -2.36 ,  -2.43 ,  -2.428,\n",
       "         -2.342,  -2.454,  -2.464,  -2.384,  -2.46 ,  -2.46 ,  -2.412,\n",
       "         -2.424,  -2.434,  -2.406,  -2.362],\n",
       "       [-18.292,  -5.594,  -4.768,  -4.16 ,  -3.794,  -3.932,  -3.604,\n",
       "         -3.566,  -3.61 ,  -3.522,  -3.518,  -3.46 ,  -3.428,  -3.282,\n",
       "         -3.354,  -3.234,  -3.332,  -2.63 ,  -2.526,  -2.518,  -2.502,\n",
       "         -2.398,  -2.408,  -2.446,  -2.44 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(stats[\"goal based\"]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "for s in range(1, env.nS - 1):\n",
    "    if env.grid_map[s] == 0:\n",
    "        continue\n",
    "\n",
    "    agent = Expert_global_optimal\n",
    "\n",
    "\n",
    "    ax.set_xticks(np.arange(0, int(np.sqrt(env.nS)) + 1))\n",
    "    ax.set_yticks(np.arange(0, int(np.sqrt(env.nS)) + 1))\n",
    "    probs = agent.action_probs[s]\n",
    "    draw_direction_probs(plt, env, s, probs)\n",
    "    ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(49):\n",
    "    print(i, Expert_global_optimal.action_probs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "old_net = sia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "1.00000e-04 *\n",
       "  1.0471\n",
       "[torch.FloatTensor of size 1x1]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1 = 0\n",
    "g2 = 1\n",
    "siamese_net(np.array([(g1, g2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.load(\"pretrained_nets/siamese_5x5.pt\")(np.array([(g1, g2)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# board.wait(board_timeout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrejklimkin/Documents/Coursework/2017-2018/main/source/experts-learning/nets.py:53: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(action_scores), state_values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-11.03"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(get_policy_reward_estimation(env, agent_goal_based, 'agent', 1000, 40, s_star=[0, 24]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrejklimkin/Documents/Coursework/2017-2018/main/source/experts-learning/nets.py:53: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(action_scores), state_values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  0.2266  0.1318  0.0942  0.5474\n",
       " [torch.FloatTensor of size 1x4], Variable containing:\n",
       " -2.5737\n",
       " [torch.FloatTensor of size 1x1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 1\n",
    "agent_goal_based(s, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrejklimkin/Documents/Coursework/2017-2018/main/source/experts-learning/nets.py:53: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(action_scores), state_values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  0.0607  0.4443  0.4541  0.0409\n",
       " [torch.FloatTensor of size 1x4], Variable containing:\n",
       " -0.9203\n",
       " [torch.FloatTensor of size 1x1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_simple(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(get_policy_reward_estimation(env, agent_simple, 'agent', 1000, 40, s_star=[None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agent_simple(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs = Variable(torch.FloatTensor([0.5, 0.5]))\n",
    "m = torch.distributions.Categorical(probs)\n",
    "m.log_prob(Variable(torch.LongTensor(1)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# import seaborn as sns\n",
    "# fig, ax = subplots(nrows=1, ncols=3, figsize=(12, 5))\n",
    "# for i in range(3):\n",
    "#     ax[i].set_xticks(np.arange(0, 6))\n",
    "#     ax[i].set_yticks(np.arange(0, 6))\n",
    "#     ax[i].invert_yaxis()\n",
    "\n",
    "# for i, s_star in enumerate([0, 24, None]):\n",
    "#     state_dist, state_dist_list = play_n_episodes(100, env, model_Bob, s_star)   \n",
    "#     for s in range(env.nS):\n",
    "#         value = model_Bob(s, s_star)[1].data[0][0]\n",
    "#         #states_heat_map[int(s // np.sqrt(env.nS))][s % int(np.sqrt(env.nS))] = value\n",
    "#         draw_value_anotate(ax[i], env, s, value)\n",
    "#     ax[i].imshow(state_dist, cmap='hot', interpolation='nearest')\n",
    "# #ax[0].colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "358ca92cc06e41eb97db7be4937c85c1": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "83016f50bcb348a3955ce27e2364110e": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "92d27ee2315e49858f502bdfada5a65c": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
